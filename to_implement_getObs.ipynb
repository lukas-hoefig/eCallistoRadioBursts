{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gets name, focuscode and frequency range of all observatories of a specific day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stations\n",
    "import const\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "\n",
    "frq_limit_low = 50\n",
    "frq_limit_high = 500\n",
    "\n",
    "def listFilesDay(url):\n",
    "    page = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return [node.get('href') for node in soup.find_all('a') if node.get('href').endswith('.fit.gz')]\n",
    "\n",
    "# mydate = \"/2022/01/26\"\n",
    "mydate = \"{:%Y/%m/%d}\".format(datetime.date.today())\n",
    "url = 'http://soleil.i4ds.ch/solarradio/data/2002-20yy_Callisto/'\n",
    "files = listFilesDay(url+mydate)\n",
    "\n",
    "stations = []\n",
    "for i in files:\n",
    "    parts = i.rsplit(\"_\")\n",
    "    stations.append([parts[0], parts[3][:2]])\n",
    "stations_clean = []\n",
    "for i in stations:\n",
    "    if i not in stations_clean:\n",
    "        stations_clean.append(i)\n",
    "\n",
    "def listFD(url, station):\n",
    "    print(station)\n",
    "    page = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    return [url + '/' + node.get('href') for node in soup.find_all('a') if node.get('href').startswith(station[0]) and node.get('href').endswith(station[1] + '.fit.gz')]\n",
    "\n",
    "for i in stations_clean:\n",
    "    for a, b in enumerate(listFD(url + mydate, i)):\n",
    "\n",
    "        with fits.open(b) as fds:\n",
    "            \"\"\"\n",
    "            try except -> print(fds[0].header[\"CDELT2\"])\n",
    "                          print(fds[0].header[\"CRVAL2\"] - fds[0].header[\"CDELT2\"] * fds[0].header[\"CRPIX2\"])\n",
    "            if fds[1] exists\n",
    "            \"\"\"\n",
    "            lat = fds[0].header['OBS_LAT']\n",
    "            lac = fds[0].header['OBS_LAC']\n",
    "            if lac =='S':\n",
    "                lat = -lat\n",
    "            lon = fds[0].header['OBS_LON']\n",
    "            loc = fds[0].header['OBS_LOC']\n",
    "            if loc=='W':\n",
    "                lon = -lon\n",
    "            frq_axis = fds[1].data['frequency'].flatten()\n",
    "            frq = sorted([frq_axis[0], frq_axis[-1]])\n",
    "            if frq[0]<frq_limit_low and frq[1]<frq_limit_high:\n",
    "                print(i[0],i[1], lon, lat, frq)\n",
    "            else:\n",
    "                print(\"discard: ---------------- \", i[0],i[1], lon, lat, frq)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: what frequency ranges are allowed to correlate \n",
    "\n",
    "TODO: rewrite observatories -> focus code part of class\n",
    "\n",
    "TODO: write/load observatories to/from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "import stations\n",
    "import download\n",
    "today = datetime.datetime.today()\n",
    "stats = stations.getStations(today)\n",
    "download.downloadFullDay(today, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import datetime \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime(2022,9,6)\n",
    "\n",
    "dp = data.createDay(date, station=\"ALASKA-COHOE\")\n",
    "dp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import correlation\n",
    "import datetime \n",
    "import data \n",
    "import analysis \n",
    "\n",
    "a = analysis.loadData(2022,1,3)\n",
    "\n",
    "# aaa = data.createFromTime(2022,1,3,0,0,5, station=a[0].stations[0])\n",
    "# bbb = data.createFromTime(2022,1,3,0,0,5, station=a[0].stations[1])\n",
    "# \n",
    "# cor = correlation.Correlation(bbb,aaa,3)\n",
    "# cor.calculatePeaks()\n",
    "date = datetime.datetime(2022,1,3,0,0,5)\n",
    "dp1, dp2, cor = analysis.calcPoint(2022,1,3,\"00:00:15\", a[0].stations[0], a[0].stations[1])\n",
    "\n",
    "analysis.plotEverything(dp1,dp2,cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52279f95a71c719c29b46e6649e7c2848e29d27590516e424c9feb43371b1514"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
